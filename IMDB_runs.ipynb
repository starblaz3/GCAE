{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c913c04-a53f-414b-af43-60b9b4c2dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten,MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f598cf7-9b05-47e0-9efb-5060e2180dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/IMDB Dataset.csv')\n",
    "data['review'] = data['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d115fd0-0bbc-414e-91b0-e1cfbda2bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc1adc6-05e5-4416-8656-0d51ddbc5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c244629-0124-4dbf-9d89-5d9a8f5f3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgane\\AppData\\Local\\Temp/ipykernel_14528/1430371325.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(data):\n",
    "    data['review without stopwords'] = data['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "    return data\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "data_without_stopwords = remove_stopwords(data)\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af05d68-93e2-45a4-8c69-26a462fe99a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review without stopwords</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
       "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
       "      <td>wonderful little production  the filming techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically family little boy (jake) thinks zomb...</td>\n",
       "      <td>basically family little boy  jake  thinks zomb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
       "      <td>petter mattei s  love time money  visually stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought movie right good job. wasn't creative ...</td>\n",
       "      <td>thought movie right good job  wasn t creative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>going disagree previous comment side maltin on...</td>\n",
       "      <td>going disagree previous comment side maltin on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>no one expects star trek movies high art, fans...</td>\n",
       "      <td>no one expects star trek movies high art  fans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      one of the other reviewers has mentioned that ...  positive   \n",
       "1      a wonderful little production. <br /><br />the...  positive   \n",
       "2      i thought this was a wonderful way to spend ti...  positive   \n",
       "3      basically there's a family where a little boy ...  negative   \n",
       "4      petter mattei's \"love in the time of money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  i thought this movie did a down right good job...  positive   \n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  i am a catholic taught in parochial elementary...  negative   \n",
       "49998  i'm going to have to disagree with the previou...  negative   \n",
       "49999  no one expects the star trek movies to be high...  negative   \n",
       "\n",
       "                                review without stopwords  \\\n",
       "0      one reviewers mentioned watching just 1 oz epi...   \n",
       "1      wonderful little production. <br /><br />the f...   \n",
       "2      thought wonderful way spend time hot summer we...   \n",
       "3      basically family little boy (jake) thinks zomb...   \n",
       "4      petter mattei's \"love time money\" visually stu...   \n",
       "...                                                  ...   \n",
       "49995  thought movie right good job. wasn't creative ...   \n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...   \n",
       "49997  catholic taught parochial elementary schools n...   \n",
       "49998  going disagree previous comment side maltin on...   \n",
       "49999  no one expects star trek movies high art, fans...   \n",
       "\n",
       "                                            clean_review  \n",
       "0      one reviewers mentioned watching just 1 oz epi...  \n",
       "1      wonderful little production  the filming techn...  \n",
       "2      thought wonderful way spend time hot summer we...  \n",
       "3      basically family little boy  jake  thinks zomb...  \n",
       "4      petter mattei s  love time money  visually stu...  \n",
       "...                                                  ...  \n",
       "49995  thought movie right good job  wasn t creative ...  \n",
       "49996  bad plot  bad dialogue  bad acting  idiotic di...  \n",
       "49997  catholic taught parochial elementary schools n...  \n",
       "49998  going disagree previous comment side maltin on...  \n",
       "49999  no one expects star trek movies high art  fans...  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154aca15-cc2b-4165-b2b8-70cfce2b84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = []\n",
    "sentiment = []\n",
    "for i in range(len(data_without_stopwords)):\n",
    "    reviews_list.append(data_without_stopwords.iloc[i,3])\n",
    "    sentiment.append(data_without_stopwords.loc[i,'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46ba00c-5a57-49d2-bb9a-cfb8da487c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\n",
    "\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a9cd6a-e045-4560-8e76-359010f7f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16998371-fa77-49c9-89f6-87fb3312e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            curr_word = w_line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384e0e11-b901-4a92-843e-bcc249e88140",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('glove.6B/glove.6B.300d.txt')\n",
    "\n",
    "maxLen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b8405b7-b36e-42bb-92fe-dd7ffca22921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = maxLen\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index, :] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9937af70-cb37-4d5d-9dc8-d254d6dd8e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1d4e97ae3d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23edd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(emb):\n",
    "    model = Sequential()\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "243299f6-13a5-4213-9a50-0f8b908d5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape):\n",
    "    X_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(X_indices)\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.6)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    X = Dropout(0.6)(X)\n",
    "    X = LSTM(128)(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    model = Model(inputs=X_indices, outputs=X)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f899b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_LSTM_model(emb):\n",
    "    embedding_vecor_length = maxLen\n",
    "    model = Sequential()\n",
    "    model.add(emb)\n",
    "    model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dense(128, activation='sigmoid'))\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e678d42f-abe5-4635-9ea2-d815fce26b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 300, 300)          28625700  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 300, 128)          219648    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300, 128)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 300, 128)          131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 300, 128)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,108,645\n",
      "Trainable params: 482,945\n",
      "Non-trainable params: 28,625,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "''' Uncommenting out one line would run the function and here, the model is based on LSTM and CNN '''\n",
    "# model = test_cnn(embedding_layer)\n",
    "model = LSTM_model(300)\n",
    "# model = CNN_LSTM_model(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f7455e1-cbef-4461-8117-ab1bfbc971e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea072b-c821-4d2b-89f9-9a3e9faf229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 646s 1s/step - loss: 0.6908 - accuracy: 0.5123\n",
      "Epoch 2/5\n",
      " 97/625 [===>..........................] - ETA: 8:41 - loss: 0.6772 - accuracy: 0.5437"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_indices, Y_train, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed5efd2-445e-4595-b43f-a7b7f735626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5baa9f6-6cd3-4b4d-b7b4-114b219db83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3531 - accuracy: 0.8494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3531234860420227, 0.849399983882904]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_indices, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a470061-7a09-42e5-a5d9-e13d75b5577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2568 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25684502720832825, 0.8999999761581421]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_indices, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753580ef-a77e-41f2-aaf7-6b64507adca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
